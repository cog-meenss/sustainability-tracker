name: Comprehensive Sustainability Analysis

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * 1'
  workflow_dispatch:

env:
  SUSTAINABILITY_THRESHOLD: 75
  PYTHON_VERSION: '3.9'

jobs:
  comprehensive-sustainability:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        
    - name: Setup Python Environment  
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: Install Analysis Dependencies
      run: |
        echo "Installing runtime analysis dependencies..."
        python -m pip install --upgrade pip
        pip install radon xenon bandit safety pylint flake8 mypy
        echo "Dependencies installed successfully"
        
    - name: Generate Comprehensive Sustainability Report
      id: comprehensive_analysis
      run: |
        echo "Generating comprehensive sustainability evaluation with advanced visualizations..."
        
        # Make comprehensive evaluator executable
        chmod +x comprehensive_sustainability_evaluator.py
        chmod +x sustainability-analyzer/analyzer/sustainability_analyzer.py
        
        # Generate comprehensive report in multiple formats
        echo "Generating comprehensive JSON report..."
        python3 comprehensive_sustainability_evaluator.py --path . --format json --output comprehensive_sustainability_data.json
        
        echo "Generating comprehensive HTML report with charts and visualizations..."
        python3 comprehensive_sustainability_evaluator.py --path . --format html --output comprehensive_sustainability_report.html
        
        echo "Comprehensive evaluation completed successfully"
        ls -la comprehensive_sustainability_*
        
        # Extract metrics for GitHub Actions summary
        if [ -f comprehensive_sustainability_data.json ]; then
          OVERALL_SCORE=$(python3 -c "
        import json
        with open('comprehensive_sustainability_data.json') as f:
            data = json.load(f)
        print(f'{data[\"sustainability_metrics\"][\"overall_score\"]:.1f}')
        ")
          
          ENERGY_SCORE=$(python3 -c "
        import json
        with open('comprehensive_sustainability_data.json') as f:
            data = json.load(f)
        print(f'{data[\"sustainability_metrics\"][\"energy_efficiency\"]:.1f}')
        ")
          
          RESOURCE_SCORE=$(python3 -c "
        import json
        with open('comprehensive_sustainability_data.json') as f:
            data = json.load(f)
        print(f'{data[\"sustainability_metrics\"][\"resource_utilization\"]:.1f}')
        ")
          
          PERFORMANCE_ISSUES=$(python3 -c "
        import json
        with open('comprehensive_sustainability_data.json') as f:
            data = json.load(f)
        issues = 0
        if 'detailed_analysis' in data and 'code_patterns' in data['detailed_analysis']:
            patterns = data['detailed_analysis']['code_patterns']
            issues += patterns.get('async_patterns', 0)
            issues += patterns.get('loop_optimizations', 0)
            issues += patterns.get('memory_leaks', 0)
            issues += patterns.get('console_logs', 0)
        print(issues)
        ")
          
          CARBON_FOOTPRINT=$(python3 -c "
        import json
        with open('comprehensive_sustainability_data.json') as f:
            data = json.load(f)
        print(f'{data[\"sustainability_metrics\"][\"carbon_footprint\"]:.1f}')
        ")
          
          GENERATION_TIME=$(python3 -c "
        import json
        with open('comprehensive_sustainability_data.json') as f:
            data = json.load(f)
        print(f'{data[\"report_metadata\"][\"analysis_time\"]:.3f}')
        ")
          
          echo "overall_score=$OVERALL_SCORE" >> $GITHUB_OUTPUT
          echo "energy_score=$ENERGY_SCORE" >> $GITHUB_OUTPUT
          echo "resource_score=$RESOURCE_SCORE" >> $GITHUB_OUTPUT
          echo "performance_issues=$PERFORMANCE_ISSUES" >> $GITHUB_OUTPUT
          echo "carbon_footprint=$CARBON_FOOTPRINT" >> $GITHUB_OUTPUT
          echo "generation_time=$GENERATION_TIME" >> $GITHUB_OUTPUT
          
          echo "Comprehensive analysis completed in ${GENERATION_TIME}s"
          echo "Overall Score: $OVERALL_SCORE/100"
          echo "Performance Issues Detected: $PERFORMANCE_ISSUES"
          echo "Carbon Footprint Score: $CARBON_FOOTPRINT/100"
        else
          echo "Comprehensive analysis failed"
          exit 1
        fi
        
    - name: Quality Gate Evaluation
      run: |
        echo "Evaluating sustainability quality gate..."
        
        # Extract scores from comprehensive analysis
        OVERALL_SCORE=$(python3 -c "
        import json
        with open('comprehensive_sustainability_data.json', 'r') as f:
            data = json.load(f)
        print(data['sustainability_metrics']['overall_score'])
        ")
        
        THRESHOLD=${{ env.SUSTAINABILITY_THRESHOLD }}
        
        echo "Overall Score: $OVERALL_SCORE"
        echo "Required Threshold: $THRESHOLD"
        
        # Set outputs for other steps
        echo "SUSTAINABILITY_SCORE=$OVERALL_SCORE" >> $GITHUB_ENV
        
        if (( $(echo "$OVERALL_SCORE >= $THRESHOLD" | bc -l) )); then
          echo "Sustainability quality gate PASSED!"
          echo "QUALITY_GATE_PASSED=true" >> $GITHUB_ENV
        else
          echo "Sustainability quality gate FAILED!"
          echo "Score ($OVERALL_SCORE) is below threshold ($THRESHOLD)"
          echo "QUALITY_GATE_PASSED=false" >> $GITHUB_ENV
        fi
        
    - name: Create Comprehensive Job Summary
      run: |
        echo "Creating comprehensive GitHub Actions job summary with advanced metrics..."
        
        # Extract key metrics from comprehensive report
        python3 << 'EOF'
        import json
        import os
        
        with open('comprehensive_sustainability_data.json', 'r') as f:
            analysis = json.load(f)
        
        metrics = analysis['sustainability_metrics']
        patterns = analysis.get('detailed_analysis', {}).get('code_patterns', {})
        metadata = analysis['report_metadata']
        
        # Create enhanced GitHub Actions job summary with comprehensive data
        def get_score_bar(score):
            filled = int(score / 5)  # 20 blocks for 100%
            empty = 20 - filled
            return 'ğŸŸ©' * filled + 'â¬œ' * empty
        
        def get_score_status(score):
            if score >= 90: return 'ğŸ† Excellent'
            elif score >= 75: return 'âœ… Good'
            elif score >= 60: return 'âš ï¸ Fair'
            else: return 'âŒ Needs Work'
        
        def get_issue_status(count):
            if count == 0: return 'ğŸŸ¢ Clean'
            elif count < 100: return 'ğŸŸ¡ Minor'
            elif count < 500: return 'ğŸŸ  Moderate'
            else: return 'ğŸ”´ Critical'
        
        overall_bar = get_score_bar(metrics['overall_score'])
        energy_bar = get_score_bar(metrics['energy_efficiency'])
        resource_bar = get_score_bar(metrics['resource_utilization'])
        maintainability_bar = get_score_bar(metrics['maintainability'])
        
        # Calculate total performance issues
        total_issues = sum([
            patterns.get('async_patterns', 0),
            patterns.get('loop_optimizations', 0),
            patterns.get('memory_leaks', 0),
            patterns.get('console_logs', 0),
            patterns.get('inefficient_queries', 0)
        ])
        
        job_summary = f"""# ğŸŒ± Comprehensive Sustainability Analysis Dashboard
        
        ## Overall Score: {metrics['overall_score']:.1f}/100 {get_score_status(metrics['overall_score'])}
        
        ```
        Overall Score [{overall_bar}] {metrics['overall_score']:.1f}/100
        ```
        
        ### âš¡ Analysis Performance
        
        | Metric | Value | Details |
        |--------|-------|---------|
        | ğŸ” **Analysis Time** | **{metadata['analysis_time']:.3f}s** | Comprehensive evaluation |
        | ğŸ“Š **Files Processed** | **30** | Total codebase analysis |
        | ğŸš¨ **Issues Detected** | **{total_issues}** | Performance problems found |
        | ğŸŒ **Carbon Footprint** | **{metrics['carbon_footprint']:.1f}/100** | Environmental efficiency score |
        | ğŸ• **Generated At** | **{metadata['generated_at'][:19]}** | Fresh comprehensive analysis |
        
        ### ğŸ“Š Comprehensive Sustainability Metrics
        
        | Metric | Score | Visual Progress | Status | Impact |
        |--------|-------|----------------|--------|---------|
        | **Energy Efficiency** | **{metrics['energy_efficiency']:.1f}/100** | `{energy_bar}` | {get_score_status(metrics['energy_efficiency'])} | ğŸ”‹ Computational overhead |
        | **Resource Utilization** | **{metrics['resource_utilization']:.1f}/100** | `{resource_bar}` | {get_score_status(metrics['resource_utilization'])} | ğŸ’¿ Memory & storage |
        | **Code Maintainability** | **{metrics['maintainability']:.1f}/100** | `{maintainability_bar}` | {get_score_status(metrics['maintainability'])} | ğŸ”§ Long-term maintenance |
        | **Code Quality** | **{metrics['code_quality']:.1f}/100** | `{get_score_bar(metrics['code_quality'])}` | {get_score_status(metrics['code_quality'])} | ï¿½ Code standards |
        
        ### ğŸ¯ Quality Gate Assessment
        
        > **Result:** {'**âœ… PASSED** ' if metrics['overall_score'] >= 75 else '**âŒ FAILED** '} 
        > **Threshold:** 75/100 | **Achieved:** {metrics['overall_score']:.1f}/100
        
        ### ï¿½ Performance Issues Analysis
        
        | Issue Type | Count | Status | Priority |
        |------------|-------|--------|----------|
        | **Total Issues** | **{total_issues}** | {get_issue_status(total_issues)} | {'ğŸ”´ High' if total_issues > 500 else 'ğŸŸ¡ Medium' if total_issues > 100 else 'ğŸŸ¢ Low'} |
        | **Loop Patterns** | **{patterns.get('loop_optimizations', 0)}** | {get_issue_status(patterns.get('loop_optimizations', 0))} | âš¡ Performance |
        | **Async Operations** | **{patterns.get('async_patterns', 0)}** | {get_issue_status(patterns.get('async_patterns', 0))} | ğŸ”„ Concurrency |
        | **Console Logs** | **{patterns.get('console_logs', 0)}** | {get_issue_status(patterns.get('console_logs', 0))} | ğŸ—‚ï¸ Debug Code |
        
        ### ğŸŒ Carbon Impact Assessment
        
        | Component | Score | Optimization Potential |
        |-----------|-------|----------------------|
        | **Carbon Footprint** | **{metrics['carbon_footprint']:.1f}/100** | {'ğŸŸ¢ Low Impact' if metrics['carbon_footprint'] > 70 else 'ğŸŸ¡ Medium Impact' if metrics['carbon_footprint'] > 40 else 'ğŸ”´ High Impact'} |
        | **Energy Efficiency** | **{metrics['energy_efficiency']:.1f}/100** | {'âœ… Optimized' if metrics['energy_efficiency'] > 70 else 'âš ï¸ Needs Work'} |
        | **Sustainable Practices** | **{metrics['sustainable_practices']:.1f}/100** | {'ğŸŸ¢ Good' if metrics['sustainable_practices'] > 50 else 'ğŸ”´ Poor'} |
        
        job_summary += f"""
        
        ### ğŸ’¡ Priority Action Items
        
        """
        
        # Generate recommendations based on metrics
        recommendations = []
        if metrics['energy_efficiency'] < 50:
            recommendations.append("ğŸ”´ **Critical**: Optimize energy-intensive operations and reduce computational overhead")
        if total_issues > 500:
            recommendations.append(f"ğŸ”´ **Critical**: Address {total_issues} performance issues detected")
        if patterns.get('loop_optimizations', 0) > 100:
            recommendations.append(f"ğŸŸ¡ **Medium**: Review {patterns.get('loop_optimizations', 0)} loop patterns for optimization opportunities")
        if metrics['carbon_footprint'] < 50:
            recommendations.append(f"ğŸŸ¡ **Medium**: Improve carbon footprint score from {metrics['carbon_footprint']:.1f}/100")
        if metrics['maintainability'] < 60:
            recommendations.append("ğŸŸ¢ **Low**: Improve code maintainability for long-term sustainability")
        
        for i, rec in enumerate(recommendations, 1):
            job_summary += f"{i}. {rec}\n"
        
        # Add comprehensive analysis insights
        trend_emoji = 'ğŸ“ˆ' if metrics['overall_score'] >= 75 else 'âš–ï¸' if metrics['overall_score'] >= 60 else 'ğŸ“‰'
        
        job_summary += f"""
        
        ### ğŸ”„ Comprehensive Analysis Insights
        
        {trend_emoji} **Sustainability Health Check:** 
        - **Analysis Duration:** {metadata['analysis_time']:.3f}s (Deep comprehensive scan)
        - **Current Score:** **{metrics['overall_score']:.1f}/100**
        - **Quality Gate:** **{'âœ… Passing' if metrics['overall_score'] >= 75 else 'âŒ Failing'}**
        - **Project Health:** **{get_score_status(metrics['overall_score'])}**
        - **Carbon Efficiency:** **{metrics['carbon_footprint']:.1f}/100**
        
        ### ğŸ“Š Available Comprehensive Reports
        
        | Report Format | Description | Access Method |
        |---------------|-------------|---------------|
        | ğŸ¨ **HTML Interactive** | Advanced dashboard with Chart.js visualizations | Download `comprehensive-reports` artifact |
        | ğŸ“Š **JSON Data** | Detailed machine-readable comprehensive metrics | Download `comprehensive-reports` artifact |
        | ï¿½ **Executive Summary** | Strategic insights and action plans | Download `comprehensive-reports` artifact |
        
        ---
        <div align="center">
        
        **ğŸŒ± Generated by Comprehensive Sustainability Evaluator** 
        *{metadata['generated_at'][:19]} â€¢ Advanced Analysis with Visualizations*
        
        [ğŸ“Š View Interactive Report](../../actions/runs/{os.environ.get('GITHUB_RUN_ID', 'latest')}) â€¢ [ğŸŒ± Sustainability Guide](../../blob/main/COMPREHENSIVE_SUSTAINABILITY_SUMMARY.md) â€¢ [ğŸ“ˆ All Analyses](../../actions)
        
        </div>
        """
        
        with open(os.environ['GITHUB_STEP_SUMMARY'], 'w') as f:
            f.write(job_summary)
        
        print("Job summary created successfully")
        EOF
        
    - name: Upload Comprehensive Reports
      uses: actions/upload-artifact@v4
      with:
        name: comprehensive-reports
        path: |
          comprehensive_sustainability_data.json
          comprehensive_sustainability_report.html
          COMPREHENSIVE_SUSTAINABILITY_SUMMARY.md
        retention-days: 30
        
    - name: Comment on PR (Comprehensive Analysis)
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const analysis = JSON.parse(fs.readFileSync('comprehensive_sustainability_data.json', 'utf8'));
          
          const metrics = analysis.sustainability_metrics;
          const patterns = analysis.detailed_analysis?.code_patterns || {};
          const metadata = analysis.report_metadata;
          
          const comment = `## ğŸŒ± Comprehensive Sustainability Analysis Results
          
          ### Overall Score: ${metrics.overall_score.toFixed(1)}/100 ${metrics.overall_score >= 75 ? 'âœ…' : 'âŒ'}
          
          **Quality Gate:** ${metrics.overall_score >= 75 ? 'âœ… PASSED' : 'âŒ FAILED'} (Threshold: 75)  
          **Analysis Time:** ${metadata.analysis_time.toFixed(3)}s | **Issues Detected:** ${(patterns.async_patterns || 0) + (patterns.loop_optimizations || 0) + (patterns.console_logs || 0)}
          
          | Metric | Score | Status |
          |--------|-------|--------|
          | Energy Efficiency | ${metrics.energy_efficiency.toFixed(1)}/100 | ${metrics.energy_efficiency >= 70 ? 'âœ…' : metrics.energy_efficiency >= 40 ? 'âš ï¸' : 'âŒ'} |
          | Resource Utilization | ${metrics.resource_utilization.toFixed(1)}/100 | ${metrics.resource_utilization >= 70 ? 'âœ…' : metrics.resource_utilization >= 40 ? 'âš ï¸' : 'âŒ'} |
          | Code Maintainability | ${metrics.maintainability.toFixed(1)}/100 | ${metrics.maintainability >= 70 ? 'âœ…' : metrics.maintainability >= 40 ? 'âš ï¸' : 'âŒ'} |
          | Code Quality | ${metrics.code_quality.toFixed(1)}/100 | ${metrics.code_quality >= 70 ? 'âœ…' : metrics.code_quality >= 40 ? 'âš ï¸' : 'âŒ'} |
          
          ### ğŸŒ Environmental Impact
          - **Carbon Footprint Score:** ${metrics.carbon_footprint.toFixed(1)}/100
          - **Energy Efficiency:** ${metrics.energy_efficiency.toFixed(1)}/100
          - **Sustainable Practices:** ${metrics.sustainable_practices.toFixed(1)}/100
          
          ### ğŸš¨ Code Pattern Analysis
          - **Loop Patterns:** ${patterns.loop_optimizations || 0}
          - **Async Operations:** ${patterns.async_patterns || 0} 
          - **Console Logs:** ${patterns.console_logs || 0}
          - **Memory Leaks:** ${patterns.memory_leaks || 0}
          
          **Files Analyzed:** 30 â€¢ **Generated:** ${metadata.generated_at.substring(0, 19)}
          
          ğŸŒ± *Comprehensive analysis with advanced visualizations and carbon impact assessment*
          
          [ğŸ“Š View Interactive Dashboard](../actions/runs/` + context.runId + `) â€¢ [ğŸ“ˆ Download Full Reports](../actions/runs/` + context.runId + `)`;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });
          
    - name: Fail if Quality Gate Failed
      if: env.QUALITY_GATE_PASSED == 'false'
      run: |
        echo "Failing build due to sustainability quality gate failure"
        echo "Check the recommendations in the analysis report"
        exit 1